Reqs for chatting system 
    -- start chatting page 
    -- two person chatting system 
    -- links for both of them 
    -- Qr code both people 
    -- secret code for both of them 
    -- secret code matching system and error system 
    -- send and recieve message 
    -- end the session 
    -- someone end the page accidentally 
        -- the url should work
        -- the person can open the url 
        -- same landindg page 
        -- put the ssecret code in 
        -- the chat should be displayed as it is 
    -- the chat destroyed only after ending the chat and a timeout system to detect inactivity 
    



database schema  -- 
    -- example 
       --  key (time_stamp for hash + username)
            -- ex - 5DEC20231209ABHI 
       -- value (message send )
            -- "Hi"

    Full storage system
        -- two people name ABHI and ANNY 
        -- timestamp+name can be the unique indetifer
        -- mesaage_hash = 23AHi7
        -- ex - 23AHi7 {
        5DEC2023120912ABHI : "HI",
        5DEC2023120913ANNY : "HEY",
        5DEC2023120914ABHI : "what u doing",
        5DEC2023120925ABHI : "Any plans this weekend ?",
        5DEC2023120925ANNY : "Nothing rn"

        }

        -- one other option is like this 
        -- exampel , use hash for the indentifier

        session_id = "23AHi7"
        {
            name_1 = "test1"
            name_2 ="test2"
            [
                {
                    "sender": "test1",
                    "timestamp": "2024-05-23T15:01:23.456789",
                    "message": "Hello!"
                },
                {
                    "sender": "test2",
                    "timestamp": "2024-05-23T15:02:10.123456",
                    "message": "Hi there!"
                },
                {
                    "sender": "test1",
                    "timestamp": "2024-05-23T15:03:45.789012",
                    "message": "How are you?"
                },
                {
                    "sender": "test2",
                    "timestamp": "2024-05-23T15:04:30.456789",
                    "message": "I'm good, thanks! How about you?"
                }
            ]
        }

	-- redis hash 
		-- chat-hash (key) , val as list of [name1, name2] 
        
	-- mongodb 
		-- hash as id
		-- chat_id = "AH27f2"
			{ "Abhi": ["Hey"],
			   "Anny": ["hi","how are you" ]
			   "Abhi": ["I am good"]
			}

    
    -- Final decision for the database 
        -- using mongodb for message storage 
        -- redis for session as pre storage 
        -- design for mongodb 
    
    -- the designs system to store and fecth the messages

        --end points -
            -- /login_user


        -- def handle messages()
            -- to store the messages

        -- def chat_one()
            -- tpo fetch the message and pass to the template






Font end -- 

    (chat-register)
    -- Chat start page (chat-register.html)
    -- chat body page ( chat-redister-body.html)
        
        (input)
        -- input First participant name
        -- input Second participant name
        -- (register user) button 

        (output)
        -- participant short url 
        -- participant qr code 
        -- copy link functionality



Backend -- 

    (chat_user_sign_up) (get) function (submit_user_details)
    -- read the input (jasionfy it )
    -- generate the hash 
    -- generate the dynamic link 
    -- store in db 
        -- hash 
        -- name 1 
        -- name 2 
    -- genrate the chat link 
    -- generate the qr code 

    (chat_user_hash) (post)
    -- class, methods and functions -- 
        -- Post method to catch the input 
        -- hash generation 
        -- two db 
            -- chat-hash
        -- get method to fetch the url and generate the qr code 
   


    
    -- Enter chat page for one perosn  
        -- Hello Name should be written
        -- enter the secret code 
        -- Get in button

    -- chat page 
        -- show the opposite name in above 
        -- input field box 
        -- send button 
        -- Endchat button (both sides of partcipant)
            -- if any one clicks that button display chat has ended to other person 
            







Backend design thinking 
    -- Db is not needed as the chat record is not stored 
    -- Chat record also should be destroyed after the chat eneded 
    -- The session has to ennd as well 
    
    -- detailed design 
        -- chat start page 
            -- after clicking the start chat button on the page
            -- session_id generated by hash 
                -- two hash for url as well 
            -- generate the db in the mongodb for messages 
            -- two link ? 
                -- genration of page 
                    db for page generation
                    seesion_id = "hash"
                    {
                        name1 = "Dummy1"
                        name2 = "Dummy2"

                        
                    }
                -- this data can be retrived with db file and can be used for validation purpose
        
        -- chat landing page 
                -- display hello 
                -- enter the name for login 
                -- validate the login
        
        -- chat page   
            -- input message (store in the database)
            -- send button 
                -- send the message to other side 
                    -- store in the database
                --- display the message on the other side 
                --- display the time for message 

            -- websocket for connecteion on server and clint side 
            --  Client-Side:
                -- The user types a message and hits send.
                -- The client-side application captures the message, packages it (e.g., in JSON format), and sends it through the WebSocket connection to the server.

            -- Server-Side:
                -- The server receives the message.
                -- The server processes the message (e.g., checking for forbidden content, adding timestamps).
                -- The server stores the message in the database if persistence is required.
                -- The server broadcasts the message to the intended recipient(s) via their WebSocket connections.
            







Reusable components -- 
	-- hashing system
	-- qr code generation 
	-- tiny-url generation 
	-- input and output fields




-- develop
	-- chat start system
	-- message sending system
	-- message receiving system 
	-- chat ending system 
	-- dynamic chat popping and UI changing 
	-- notification service 
	-- Timeout system
	-- chat storage system 
        -- order of chat message is imp
    -- chat destruction system 
    -- timeout system


--------------------------------------------------------------------------------------------

 The color theme --- 

 make the dark-theme

color coding scheme - 

all the theme matches to this color - 

light-theme - 

    main-body - #ffffff
    continer/heading-boxes - #ffffff
    footer-header-color - #e9ecef 
    main-continer-color - #19A7CE
    blue-font-color - #146C94
    button-color - #19A7CE



dark - theme - 
    - the backgrond changes to black (main-body) - #1e1e1e
    - continer/heading-boxes to black - #1e1e1e
    - footer-header-color - #343a40
    - white text to black - #00000
    - blue-font-color - #19A7CE
    - button-color - #19A7CE



suggestion -- 

Main Body: #121212 (a very dark grey)
Container/Heading Boxes: #1e1e1e (a slightly lighter dark grey)
Footer Header Color: #343a40 (a dark grey)


------------------------------------------------------------------------------------


docker notes -- 
- deployment is easy 

- problems 
    - redis recovery service 
    - mongo revovery service 
    - bulk data insertion system for mongo 
        - store the bulk data somewhere else
        - make a small client file that can be run outside just one repo
        - run it to insert the data 
    - sending the connect message on the site and make a recovery for it
    - wesite testing has to be updated

    - for the backup 
        - put them in s3 bucket 
        - dumb the backup file to s3 bucket
        - mount the recovery data from s3 bucket to redis and mongo container
        - put the bulk data insertion as well



- deploymnet and making the image
    - deploy the image and push to the docker repo
        - make the image making and pushing pocess auotmated and push to the repo
        - the machine pull the latest image and apply the new one
    - Clean the repo and put the codes in differrent repo for development of different parts
        - mongo code in mongo
        - testing in diffeent repo
        - dockerization in different repo



- for deploymnet
    - pull the image of webiste
    - run the docker compose 
    - get the redis backup data
    - get the mongo backup data
    - attach the data and run the database containers


-- the backup appoach 
    - docker compose down
    - docker compose up -d

store all the backups in S3 later

#mongo
-- creting backups (auotmated)
    - docker exec mongo mongodump --out /backup/db-backup
- to restore data
    - docker exec mongo mongorestore --drop /backup/db-backup


#redis
- creting backups (automate)
    - docker exec redis redis-cli BGSAVE

- copy the file from container to host (automate)
    - docker cp redis:/data/dump.rdb ./redis-backups/dump.rdb

- restoring the data 
    - docker cp ./redis-backups/dump.rdb redis:/data/dump.rdb


steps --

- make the script for making the auto backup of redis and mongo
- make the bulk data insertion script 
- make the data restoration script as well 
-


-----------------------------------------------------------------------------------

website summarization --

-- Use a small Language model to summarize the webiste 
-- Make a webcrawler to get the data from the website 
-- fetch the data in the model and then summarize it through the model 


-- small language model like phi-3 
-- google bert 
-- Use Python libraries like requests for fetching web pages and BeautifulSoup or lxml for parsing HTML content.
   These libraries help you extract text and other relevant information from web pages.

-- testing will be crucial phase as the 


Tips for Effective Testing:
     - Diverse Inputs: Test with diverse texts to ensure your model generalizes well across different domains and writing styles.

     - Edge Cases: Include edge cases such as very short or very long texts to check how well your model handles them.

     - Validation Set: Reserve a subset of your data as a validation set during model development to monitor performance and avoid overfitting.




the models best for summarization -- 

In conclusion, for summarization tasks, models like BERT-based variants, 
GPT-Neo, BART, and PEGASUS are well-regarded and have been successfully 
applied in various research and commercial applications. 
The choice should align with your specific needs regarding summarization quality, 
computational efficiency, and ease of integration.










The implemenattion 

The scrambing ideas for the the machine learning addition to the website as the hosting machine will be very expensive for the full machine
-- use two instance , one for hsoting the instance , one for the GPU support in aws -- G4, G5, P4 instance
-- these machine have GPU with choosing the ubuntu cuda installed images




-- I can use SSH to work on the machine
-- the other machine can talk to the GPU machine GRPC web client for bidiretional communication
-- aws lambda can be used for machine sleeping and waking up calls


-- For the code as insfrastructure I can use combination of terraform and ansible to deploy the code and run the production machine
-- grpc protocals can be use to fetch the data from one machine to other machine



reqs --

-- pip install transformers

for the LLM and ML tasks

-- the hugging face models can be a starting point to deep dive
-- LLM caching for faster responses
-- using langchain to build the models
-- using the SLM






small models list --

distilBert
gpt-neo
Tiny-bert
mobile-bert
phi-3, phi-2
orca 2



links --


https://huggingface.co/collections/open-llm-leaderboard/llm-leaderboard-best-models-652d6c7965a4619fb5c27a03
https://www.salesforce.com/blog/small-language-models/
https://medium.com/@nageshmashette32/small-language-models-slms-305597c9edf2
https://deepgram.com/ai-glossary/distilbert
https://www.datacamp.com/tutorial/phi-3-tutorial
--------------------------------------------------------------------------------------------------------

redis  recovery ------------

The goal is to get all the redis hash value out 
it should be done every 15 mins 
take all values and store in json file 
have a mechnis to push value in redis set again in case for recovery for one time 



-- database file name 
    -- redis_hash.json (store all the hash values)


-- Design 

    redis_recovery (folder)
        -- redis_recovery_fun (file)
            -- store_hash_val()
                -- store the hash value in python hashmap
            -- save_hash_to_json(dictionary, file_path)
                 -- store the hash map values in json file
            -- run_periodically()
                -- to run the save_hash_to_json periodically every 15 mins
        -- push_hash_to_redis(file)
            -- push_hash_from_json_to_redis(file_path, hash_name)
                -- push hashes val from json to redis hash


-- The redis_recovery_fun.py file shoudl run every 15 mins on server 
-- In case of redis failure it can be restored by running push_hash_to_redis 


-- Testing 
    -- make a new hash 
    -- run the redis_recovery_fun 
    -- check working 
    -- delete the database 
    -- check if failed
    -- run the push_hash_to_redis
    -- check the url redirection

--------------------------------------------------------------------------

docker steps and docker compose ---


#installation of nginx

-- make the aws instance allow the https and http traffic

static ip of machine

-- 3.128.143.84

-- install docker --
-- # Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update


-- sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin


-- docker run without sudo -

    - sudo groupadd docker
    - sudo gpasswd -a $USER docker



-- install ansible --

-- pull the docekr image
    - docker pull abhishekprakash256/personal-website-linux:latest

-- make the docker network 
    - docker network create my_network


-- run the docker conatiners

    - docker compose up -d (can save the steps)
    - docker compose down (to remove all)

    -docker run -d --name mongo --network my_network -p 27017:27017 mongo:latest
     docker run -d --name redis --network my_network -p 6379:6379 redis:latest
     docker run -d --name personal-website --network my_network -p 5000:5000 abhishekprakash256/personal-website-linux


-- install nginx 

    - sudo apt install nginx -y


-- install certbot 

    - sudo apt install certbot python3-certbot-nginx -y


-- make the certification 
    - sudo certbot certonly --non-interactive --nginx --agree`-t`os --email abhishekprakash47@gmail.com -d meabhi.me

-- put the config file in place for nginx
 - in location /etc/nginx/sites-available
  
- test the nginx 
 - sudo nginx -t

- reload nginx 
 - sudo systemctl reload nginx


-- run the conatainer or before
-- injest the data 
  cd mongo && python3 bulk_data_insertion.py

-- docker making the images -

- docker build -t <name-latest>:latest .

- to push to the docker repo
- use 
- docker tag personal-website:latest your-dockerhub-username/personal-website:latest
- docker login
- docker push your-dockerhub-username/personal-website:latest



---------------------------------------------------------------------------------------------

problems to tackle -- 

make git ignore for database files
  (Personal - website) 
- for files ingestion 
- for recovery volumes as well 

  (website deployment)

- make branch for test and main 
- make git ignore for volumes 
- the test should have docker-compose different 



-------------------------------------------------------------------

whole deployment process --

make an ec2 instance with the given IP 
install ansible 
pymongo 
get the keys from email for repo 


git clone the website deployment repo 
(make the volumes in the repo if not there (for message saving))

docker compose up -d (to start the container)

docker compose down (to kill the containers)


--------------------------------------------------------------------

The development process 

branches -- 
 - main (fully support docker)
 - docker-main (the connection are made with client using the Redis and mongo name)
 - dev (can run the database code locally using the docker container as database) (The clinet are modified)
    - in two files mongo_helper and redis_helper make the clinet to localhost
 - periodic-testing (run the test periodally for the website)
 - chore/cleanup (the clean up branch) 
 - feature/<feature_name>  (any feature name)

 - merge the branch into main 
    - git checkout <branch-name>
    - git merge main
    - git push

- Run the database in docker , ingest the data
- Run python3 app.py (to start the server)

- if running out the container use localhost as client

- if running the main app in the container use mongo and Redis as client 

