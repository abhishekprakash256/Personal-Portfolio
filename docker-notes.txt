- deployment is easy 

- problems 
    - redis recovery service 
    - mongo revovery service 
    - bulk data insertion system for mongo 
        - store the bulk data somewhere else
        - make a small client file that can be run outside just one repo
        - run it to insert the data 
    - sending the connect message on the site and make a recovery for it
    - wesite testing has to be updated

    - for the backup 
        - put them in s3 bucket 
        - dumb the backup file to s3 bucket
        - mount the recovery data from s3 bucket to redis and mongo container
        - put the bulk data insertion as well



- deploymnet and making the image
    - deploy the image and push to the docker repo
        - make the image making and pushing pocess auotmated and push to the repo
        - the machine pull the latest image and apply the new one
    - Clean the repo and put the codes in differrent repo for development of different parts
        - mongo code in mongo
        - testing in diffeent repo
        - dockerization in different repo



- for deploymnet
    - pull the image of webiste
    - run the docker compose 
    - get the redis backup data
    - get the mongo backup data
    - attach the data and run the database containers


-- the backup appoach 
    - docker compose down
    - docker compose up -d

store all the backups in S3 later

#mongo
-- creting backups (auotmated)
    - docker exec mongo mongodump --out /backup/db-backup
- to restore data
    - docker exec mongo mongorestore --drop /backup/db-backup


#redis
- creting backups (automate)
    - docker exec redis redis-cli BGSAVE

- copy the file from container to host (automate)
    - docker cp redis:/data/dump.rdb ./redis-backups/dump.rdb

- restoring the data 
    - docker cp ./redis-backups/dump.rdb redis:/data/dump.rdb


steps --

- make the script for making the auto backup of redis and mongo
- make the bulk data insertion script 
- make the data restoration script as well 
- 






